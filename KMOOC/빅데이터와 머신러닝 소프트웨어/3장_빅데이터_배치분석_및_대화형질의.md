### 배치 분석
- 많은 데이터를 큰 단위로 분석하는 분석 방법
- Spark의 RDD operation을 통해 표현 가능
1. RDD 생성
  + 병렬화된 Collection 만드는 방법: parallelize(existingCollection)->rdd   
    테스트를 위해 작은 데이터를 분산화시켜서 사용하고자 할 때 사용
  + Hadoop datasets: 아주 큰 데이터를 분산 파일 시스템에 저장하고 있을 때   
    해당하는 데이터 파일들의 위치를 textFile이라는 함수에 주면 데이터를 읽어서 RDD 생성   
    textFile(url)->rdd
    
2. RDD 변환: Element-wise 변환(각각의 원소마다 특정 변환)   
![image](https://user-images.githubusercontent.com/28378553/126091325-fe89da84-a67f-487e-820d-801348e2841f.png)   
Map: RDD에 있는 각각의 원소에 Map에 남겨진 함수를 적용해서 결과를 만들어내고, 그 결과들을 모아서 RDD를 만들어낸다   
flatMap: RDD에 있는 각각의 원소에 flatMap에 넘겨진 함수를 적용, 그 함수 결과로 나오는 iterator에 각각의 element를 다 꺼내서 flat된 RDD를 만들어낸다    
filter: RDD에서 포함된 element중에 filter 안에 표현된 조건을 만족하는 원소만 통과시켜 모은 RDD 반환   
![image](https://user-images.githubusercontent.com/28378553/126092627-62c38092-ac6e-4268-b62b-3d692a2833b8.png)   

- Pair RDD: RDD에 포함된 element가 key/value pair 형태로 되어 있는 경우. 각 key에 대해서 병렬로 수행할 수 있는 operation을 보여주거나 네트워크에서 특정 key에 해당하는 데이터를 모으는 operation을 더 보여준다   
![image](https://user-images.githubusercontent.com/28378553/126093596-8db5f834-8085-4202-b5dc-f4c308e17825.png)   
![image](https://user-images.githubusercontent.com/28378553/126093680-b5495b1f-bde0-427c-a296-2b9047670ff0.png)
- Action   
![image](https://user-images.githubusercontent.com/28378553/126093883-ec95116d-e9d4-49a9-981f-fea15c0dfdff.png)   
![image](https://user-images.githubusercontent.com/28378553/126094959-6c77d689-1a37-4c1f-ae83-faf887f9241d.png)   

- Persistence
  + in-memory computing을 활용하기 위해서 프로그램 상에서 해주는 것
  + 계산한 결과를 메모리에 유지하고싶을 때: rdd.persist   
![image](https://user-images.githubusercontent.com/28378553/126106135-ea238ecd-686b-46bf-b61c-054c5d87a9c6.png)   

### 대화형 질의
- 데이터가 구조화된 데이터일 경우 사용되는 빅데이터 분석 방법
- 대표적인 대화형 질의 언어: SQL
- 구조화된 데이터의 Operation
  + Projection: 테이블에서 어떤 컬럼만 뽑아서 보고 싶을 때 사용하는 operation
  + Selection: 특정 조건을 만족하는 row들만 뽑아서 그 결과를 보여주는 것
  + Aggregation: 하나의 컬럼에 대해서 데이터 통계를 내서 보고 싶을 때 사용
  + Join: 두 개의 테이블에 있는 데이터를 같이 보고 싶을 때 사용
- SparkSQL
  + DataFrame: a Dataset organized into named columns
  + Spark에서 sql 질의를 수행하려고 하면, 해당하는 sql 질의를 Spark가 이행하는 RDD 변환으로 바꿔서 수행
  + ![image](https://user-images.githubusercontent.com/28378553/126110750-01773cd1-cbad-4f96-9dec-6e458fe7a710.png)
  + ![image](https://user-images.githubusercontent.com/28378553/126111647-acdfeadc-134b-4336-a13e-dfee6c90a23e.png)
  + ![image](https://user-images.githubusercontent.com/28378553/126111673-c8a7a6d0-055d-41fc-a792-1ed4e6b5ab78.png)
  + 전통적인 SQL string을 사용하기 위해서는 먼저 데이터프레임을 sql 임시 뷰로 등록해야 한다   
  ![image](https://user-images.githubusercontent.com/28378553/126205776-62d54ffb-0636-435b-b60b-fa1cd84565e3.png) 
