### 스트림 처리
- 실시간으로 들어오는 데이터를 빠르게 분석하는 빅데이터 분석 방법
- 기존의 Batch 분석에서는 분석해야 할 데이터가 고정되어 있다. 분석할 데이터가 바뀌지 않는다.
- 스트림 데이터에서는 분석해야 할 데이터가 계속 들어온다
- 스트림 데이터에서 들어오는 하나의 데이터 instance를 이벤트라고 한다
- processing time: 시스템에 이벤트가 들어오는 시점
- Unbounded data
- Event time != data processing time
- late data를 잘 처리하는 것이 중요
- Window operation: 특정 시간 인터벌 안에 있는 이벤트들을 처리하기 위해 사용하는 operation
- 스트림 처리 방식
  + Continuous: Storm, Heron, Flink - 빠르게 데이터 처리 가능하지만, 장애 복구 방법에서 더 어려움. 질의가 계속해서 수행되고 있고, 데이터가 질의를 통과하면서 질의의 상태를 변경
  + Micro-batch system: SparkStreaming - 스트림 처리를 위해서 작은 단위의 Batch를 계속해서 수행, 장애 복구에서는 장점, 빠른 분석을 요구할 때는 사용이 어렵다. state를 수정 불가능한 state로 바꾸고, 계속해서 계산하는 것이 아니라 작고, deterministic하고 stateless한 task로 쪼개서 계속 Micro-batch를 수행
- 스트림 분석 패턴
  + Element-wise transformation: element마다 변환
  + Aggregation
    - Group by: 새로운 데이터가 들어올 때마다 group by가 수행
    - Windowing: 어떤 특정 시간에 해당하는 데이터를 모아서 분석, 프로세싱 시간 기반의 Window나 이벤트 시간 기반의 Window
  + Composite: Element-wise transformation, Aggregation을 합쳐서 병합해서 사용하는 것
![image](https://user-images.githubusercontent.com/28378553/126210686-a3a5211e-2e98-4503-9374-744fb80188ba.png)   
![image](https://user-images.githubusercontent.com/28378553/126210886-4a8a76c5-e22e-44f7-a127-ed3a9c6c81e3.png)   
- Watermark: delay를 감안해서 '어떤 시점까지 기다리면 해당 이벤트가 다 들어올 것이다' 추측을 하는 것   
![image](https://user-images.githubusercontent.com/28378553/126211666-d3d28d0c-c5ac-4d20-8495-0d846977c3a7.png)      
Watermark은 완벽할 수 없지만 잘 선언하면 시스템이 안정적으로 스트림 처리를 할 수 있다   
워터마크 선언이 너무 느리면 해당하는 결과를 보는 것이 지연된다(워터마크 시점에서 결과가 나오기 때문)   
워터마크가 너무 빠르면 어떤 데이터는 늦게 들어오는데 워터마크 전에 해당 데이터가 안 들어왔기 때문에 고려되지 않는다   
- Micro-batch   
![image](https://user-images.githubusercontent.com/28378553/126213130-7cb9893a-0824-48ea-ab4d-f5b82eaea3de.png)   
해당 타임 인터벌에 새로운 데이터가 들어올 때 이전 타임 인터벌까지 계산된 결과와 합해서 그 해당 인터벌의 결과를 만들어내는 방식
